#  TP Final Computer Vision: Reconocimiento y Detecci贸n de Razas de Perros

**Autor:** Bravi Eugenio B-6600/1

##  Resumen del Proyecto

Este proyecto es un Trabajo Pr谩ctico Final de Computer Vision que aborda el desaf铆o de la detecci贸n y clasificaci贸n de razas de perros en im谩genes. Se construye una soluci贸n integral que abarca desde la preparaci贸n del dataset y la implementaci贸n de bases de datos vectoriales para b煤squeda por similitud, hasta el entrenamiento de modelos de clasificaci贸n profunda y la creaci贸n de un pipeline completo de detecci贸n + clasificaci贸n, culminando con la optimizaci贸n de modelos y un script de anotaci贸n autom谩tica.

Las principales tecnolog铆as utilizadas incluyen:
*   **TensorFlow/Keras**: Para la construcci贸n y entrenamiento de modelos de Deep Learning.
*   **FAISS**: Para la creaci贸n de una base de datos vectorial eficiente para la b煤squeda por similitud de im谩genes.
*   **Ultralytics YOLOv8**: Para la detecci贸n de objetos (perros) en im谩genes complejas.
*   **Gradio**: Para la creaci贸n de interfaces de usuario interactivas y demostrativas.
*   **KaggleHub**: Para la descarga del dataset.
*   **OpenCV (cv2)**: Para el preprocesamiento y manipulaci贸n de im谩genes.
*   **scikit-learn**: Para el c谩lculo de m茅tricas de evaluaci贸n.
*   **TensorFlow Lite**: Para la optimizaci贸n y cuantizaci贸n de modelos.

##  Etapas del Proyecto

El proyecto se divide en varias etapas clave:

### 1. Preparaci贸n del Dataset y Base de Datos Vectorial para B煤squeda por Similitud

*   **Descarga y An谩lisis del Dataset**: El dataset `70-dog-breedsimage-data-set` se descarga de Kaggle. Se realiza un an谩lisis inicial que revela un desequilibrio significativo en la distribuci贸n de las clases (razas de perros).
*   **Balanceo del Dataset con Data Augmentation**: Para mitigar el desbalance, se implementa una estrategia de aumento de datos (`data_augmentation`) que genera nuevas im谩genes para las clases minoritarias, utilizando transformaciones como volteo horizontal/vertical, rotaci贸n, contraste y brillo.
*   **Base de Datos Vectorial (FAISS)**:
    *   Se utiliza el modelo pre-entrenado **ResNet50** (sin la capa superior) como extractor de caracter铆sticas para generar embeddings (representaciones vectoriales) de las im谩genes.
    *   Estos embeddings se indexan utilizando **FAISS (Facebook AI Similarity Search)**, permitiendo b煤squedas eficientes de im谩genes similares basadas en la distancia euclidiana (L2).
*   **Buscador por Similitud (Gradio)**: Se desarrolla una interfaz interactiva con Gradio que permite al usuario subir una imagen y encontrar las 10 razas de perros m谩s similares en la base de datos, mostrando la imagen de entrada, la raza predicha por voto mayoritario y las im谩genes y clases similares.
*   **Evaluaci贸n del Buscador**: Se calcula el **NDCG@10 (Normalized Discounted Cumulative Gain)** para evaluar la calidad del ranking de similitud. Se observa una mejora significativa en el NDCG@10 (de ~0.78 a ~0.83) despu茅s de aplicar el aumento de datos, demostrando la importancia de un dataset balanceado.

### 2. Entrenamiento y Evaluaci贸n de Modelos de Clasificaci贸n

*   **Pipeline de Entrenamiento y Evaluaci贸n**: Se implementa una funci贸n `train_test` que gestiona el preprocesamiento de etiquetas (one-hot encoding), la creaci贸n de `tf.data.Dataset`, la compilaci贸n del modelo (optimizador Adam, `categorical_crossentropy`), y el uso de callbacks avanzados (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint). La funci贸n tambi茅n visualiza el historial de entrenamiento (accuracy y loss) y genera un reporte de clasificaci贸n completo (precision, recall, f1-score) y visualizaciones de predicciones.
*   **Modelos Entrenados**:
    *   **Modelo Convolucional (desde cero)**: Una red neuronal convolucional personalizada. Este modelo mostr贸 un rendimiento modesto (accuracy de prueba de ~0.46), lo que resalta la complejidad de la tarea sin un pre-entrenamiento.
    *   **ResNet50 con Transfer Learning (Finetuning)**: Se utiliza ResNet50 pre-entrenado en ImageNet como extractor de caracter铆sticas, seguido de capas densas personalizadas. Este modelo alcanz贸 un rendimiento significativamente superior (accuracy de prueba de ~0.88), demostrando la eficacia del transfer learning para esta tarea.
*   **Carga de Modelos y Nuevos ndices FAISS**: Se cargan los pesos de los modelos entrenados y se generan nuevos 铆ndices FAISS utilizando las capas de embedding (`densa_embbeding`) de estos modelos, permitiendo comparar su rendimiento en la b煤squeda por similitud.
*   **Buscador por Similitud V2 (Gradio)**: Se mejora la interfaz de Gradio para permitir al usuario seleccionar entre los diferentes modelos (ResNet50 original, ResNet50 con finetuning, CNN desde cero) para realizar la b煤squeda por similitud.
*   **Comparaci贸n de Modelos en B煤squeda por Similitud**: Se eval煤a el NDCG@10 para cada uno de los modelos entrenados como extractores de caracter铆sticas para la b煤squeda por similitud. Se observa que el modelo ResNet50 con finetuning mantiene un alto rendimiento, ligeramente inferior al ResNet50 base en esta m茅trica.

### 3. Pipeline de Detecci贸n y Clasificaci贸n (YOLO + Clasificador)

*   **Integraci贸n de Detecci贸n y Clasificaci贸n**: Se crea un `DogDetectionClassificationPipeline` que combina:
    *   **Detecci贸n de objetos con YOLOv8n**: Se utiliza un modelo YOLOv8n pre-entrenado para identificar y localizar perros en im谩genes.
    *   **Clasificaci贸n de razas**: La porci贸n de perro detectada por YOLO es recortada y pasada al modelo de clasificaci贸n de razas (el `modelo_transfer_learning` previamente entrenado) para determinar su raza.
*   **Interfaz Gradio para el Pipeline Completo**: Se implementa una interfaz de usuario en Gradio que permite al usuario subir una imagen compleja, y el pipeline detecta los perros, clasifica sus razas y muestra la imagen anotada con los bounding boxes y las etiquetas de raza, junto con un JSON de las detecciones.

### 4. Evaluaci贸n del Pipeline Completo y Optimizaci贸n

*   **Anotaci贸n de Im谩genes Complejas**: Se descargan y anotan manualmente un conjunto de im谩genes "complejas" (con m煤ltiples perros, o perros en diversos contextos) para servir como Ground Truth para la evaluaci贸n del pipeline completo. Se utiliza `cv2` para visualizar estas anotaciones.
*   **Evaluaci贸n del Pipeline**: Se define una funci贸n `evaluate_pipeline` para medir el rendimiento del pipeline de detecci贸n y clasificaci贸n. Esta funci贸n calcula m茅tricas clave como **Precision, Recall, F1-Score, Mean IoU (Intersection over Union)** para la detecci贸n, y un **mAP@0.5** (Mean Average Precision a un umbral IoU de 0.5) para evaluar la combinaci贸n de detecci贸n y clasificaci贸n.
    *   Los resultados obtenidos (Precision: ~0.76, Recall: ~0.62, F1-Score: ~0.67, Mean IoU: ~0.87, mAP@0.5: ~0.65) indican un buen rendimiento en la clasificaci贸n de las detecciones correctas y calidad de las bounding boxes, pero una limitaci贸n notable en el `Recall` de la detecci贸n (es decir, no detecta todos los perros presentes).
*   **Optimizaci贸n de Modelos con TensorFlow Lite**: El `modelo_transfer_learning` se cuantiza a formato **INT8** utilizando TensorFlow Lite. Esto reduce significativamente el tama帽o del modelo y acelera la inferencia.
    *   Se implementa una clase `classify_image_tflite` para medir el tiempo de inferencia del modelo optimizado.
    *   La evaluaci贸n del pipeline con el modelo optimizado muestra m茅tricas de rendimiento id茅nticas al modelo original, pero con una **velocidad de inferencia aproximadamente el doble de r谩pida** (de ~40ms a ~20ms), confirmando la eficacia de la cuantizaci贸n.
*   **Script de Anotaci贸n Autom谩tica**: Se desarrolla un script (`script_anotacion`) que utiliza el pipeline de detecci贸n y clasificaci贸n para procesar autom谩ticamente una carpeta de im谩genes, generar anotaciones en formatos **YOLO** (`.txt`) y **COCO** (`.json`), y opcionalmente guardar las im谩genes con las anotaciones dibujadas. Este script es 煤til para automatizar la creaci贸n de datasets anotados.

## 锔 C贸mo Ejecutar el Proyecto

Este proyecto est谩 dise帽ado para ejecutarse en un entorno como Google Colab debido a las dependencias de GPU para el entrenamiento y la inferencia de modelos de Deep Learning.

1.  **Abrir en Google Colab**: Sube el archivo `TP_FINAL_CV.ipynb` a Google Colab.
2.  **Ejecutar Celdas**: Ejecuta cada celda del notebook secuencialmente.
    *   La primera vez que ejecutes, se instalar谩n las dependencias (`kagglehub`, `faiss-cpu`, `gdown`, `ultralytics`).
    *   Se descargar谩n los datasets y los modelos pre-entrenados/guardados.
    *   Las interfaces de Gradio se lanzar谩n y proporcionar谩n enlaces p煤blicos para su interacci贸n.
